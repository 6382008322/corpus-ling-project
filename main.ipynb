{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML; display(HTML(\"<style>.container { width:100% !important; }</style>\")) # make screen full width\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from util.wiki import *\n",
    "from util.util import *\n",
    "from util.evaluation import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Wikidump and Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wikicorpus = 'wiki_th'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [10:49<00:00, 32.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of lines: 7233200\n"
     ]
    }
   ],
   "source": [
    "# combind wiki text from directories generated by wikiextractor\n",
    "create_wikidump_text(wikicorpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# the wikidump is large, so we use one portion of it.\n",
    "# reduce_wikidump(wikicorpus, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# explore wiki text\n",
    "with open(f'_/wikidump/{wikicorpus}_text.txt') as f:\n",
    "    obj = f.read()\n",
    "    print(obj[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# generate fractions of corpus from text file\n",
    "# create corpus_i.txt (we split to 10 batches)\n",
    "create_corpus_batch(wikicorpus, begin=1, end=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# combind corpus fractions\n",
    "# combind corpus_i.txt\n",
    "create_corpus_combind(wikicorpus) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigram finished in 0:01:55\n",
      "freq finished in 0:01:44\n",
      "t finished in 0:01:10\n",
      "chi finished in 0:01:10\n"
     ]
    }
   ],
   "source": [
    "create_top_bigrams(wikicorpus, n_bigrams=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wikicorpus, corpus = 'wiki_th', 'pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# create word corpus\n",
    "# create_corpus_word_pt() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10273/10273 [12:40<00:00, 13.51it/s]\n",
      "100%|██████████| 10273/10273 [13:13<00:00, 12.95it/s]\n",
      "100%|██████████| 10273/10273 [13:10<00:00, 12.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# create merge corpora\n",
    "create_corpus(corpus, wikicorpus, ['chi', 't', 'freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# write files that mallet needs\n",
    "prepare_mallet_data(corpus, ['word', 'chi', 't', 'freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w2v finished in 0:13:06\n"
     ]
    }
   ],
   "source": [
    "# train word2vec\n",
    "train_w2v(corpus, ['word', 'chi', 't', 'freq'], vector_size=100, min_count=1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# explore word2vec\n",
    "model = Word2Vec.load(f'corpus/{corpus}/w2v_model')\n",
    "' '.join([x for (x,y) in model.wv.similar_by_word('โรงเรียน')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Update Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "corpora, types, n_topics, n_keys = ['pt'], ['word', 'chi', 't', 'freq'], [10, 50, 100], [20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dn  chi  0.0000\n",
      "dn  t    0.0580\n",
      "dn  freq 0.0596\n"
     ]
    }
   ],
   "source": [
    "# train document information and merged percentage\n",
    "add_train_info(corpora, types)\n",
    "add_merged_percentage(corpora, types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus: pt, add silhouette\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.37s/it]\n",
      "100%|██████████| 1/1 [00:34<00:00, 34.35s/it]\n",
      "100%|██████████| 1/1 [02:17<00:00, 137.53s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.37s/it]\n",
      "100%|██████████| 1/1 [00:34<00:00, 34.44s/it]\n",
      "100%|██████████| 1/1 [02:17<00:00, 137.75s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.39s/it]\n",
      "100%|██████████| 1/1 [00:34<00:00, 34.35s/it]\n",
      "100%|██████████| 1/1 [02:18<00:00, 138.38s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.38s/it]\n",
      "100%|██████████| 1/1 [00:34<00:00, 34.20s/it]\n",
      "100%|██████████| 1/1 [02:17<00:00, 137.63s/it]\n"
     ]
    }
   ],
   "source": [
    "# silhouette \n",
    "add_silhouette(corpora, types, n_topics, n_keys, rounds=range(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Export results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "corpora = ['ny', 'ye', 'cn', 'dp', 'pt', 'wn']\n",
    "types, n_topics, n_keys = ['word', 'chi', 't', 'freq'], [10, 50, 100], [20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# export Log-Likelihood, Silhouette, Merged Percentage\n",
    "export_results(corpora, types, n_topics, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### export doctok to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:02<00:00,  5.48it/s]\n"
     ]
    }
   ],
   "source": [
    "export_doc_tok()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### show top bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wikicorpus, types = 'wiki_en', ['chi', 't', 'freq']\n",
    "for type_ in types:\n",
    "    print('\\n',type_)\n",
    "    with open(f'corpus/{wikicorpus}/top_bigrams_{type_}.txt') as f:\n",
    "        lines = f.read().strip().split('\\n')\n",
    "        lines = lines[:20]\n",
    "        text = ', '.join([line.replace('\\t', ' ') for line in lines])\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### show keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "word\n",
      "\n",
      "- คน สั่ง รอ ร้าน โต๊ะ พนักงาน ทำ นั่ง เดิน ตอน ทาน ผม ดู เวลา เหมือน ลูกค้า บริการ คิว ตัว เค้า\n",
      "- เนื้อ ดี ทาน อร่อย น้ำ สลัด เลือก ผัก ซอส บาท ราคา จาน หมู เมนู อาหาร สั่ง ญี่ปุ่น สด ข้าว ชอบ\n",
      "- ร้าน นั่ง กาแฟ ดี บรรยากาศ ดื่ม เครื่อง เย็น ตกแต่ง อาหาร รัก เหมาะ เค้ก สวย เลือก สั่ง ชอบ เล่น หวาน รสชาติ\n",
      "- อาหาร ร้าน ดี ทาน ราคา รสชาติ บริการ เมนู คน ผม สำหรับ อร่อย ทำ สาขา บรรยากาศ ดู ไทย เลือก จาน แพง\n",
      "- หวาน ทาน อร่อย ดี รส รสชาติ ร้าน บาท น้ำ ขนม หอม ตัว เมนู นม ชิ้น ชอบ เลือก เค้ก ขนมปัง ลอง\n",
      "- ร้าน รถ จอด ถนน ขาย ซอย ราคา หน้า บาท นั่ง ริม หา ติด เดิน แถว ขับ มือ ฝั่ง โต๊ะ ซ้าย\n",
      "- กิน อร่อย ร้าน คน ลอง ชอบ สั่ง ดี ดู เค้า เหมือน ชิม เพื่อน แวะ ตอน รู้ ก้อ ราคา รสชาติ แนะนำ\n",
      "- หมู ร้าน น้ำ อร่อย ก๋วยเตี๋ยว เส้น ข้าว ทาน ซุป สั่ง บาท เนื้อ ใส่ ดี เป็ด ชาม ไข่ ชิ้น นุ่ม รสชาติ\n",
      "- ผัด อาหาร ปลา กุ้ง อร่อย ดี น้ำ สด ทอด จาน รสชาติ ปู ตัว สั่ง ข้าว เมนู ทาน ทะเล ร้าน ไข่\n",
      "- ไก่ อร่อย ร้าน น้ำ หมู ทาน ข้าว ดี ทอด จิ้ม รสชาติ ย่าง อาหาร เมนู เผ็ด สั่ง จาน รส ชอบ แกง\n"
     ]
    }
   ],
   "source": [
    "corpora, types, = ['wn'], ['word']\n",
    "for corpus in corpora:\n",
    "    for type_ in types:\n",
    "        print('\\n'+type_+'\\n')\n",
    "        keys = get_keys(corpus, type_, 10, 0, 20)\n",
    "        text = '- ' + '\\n- '.join([' '.join([k for k in key]) for key in keys])\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# migrate new data\n",
    "corpora, types, n_topics, n_keys = ['dn', 'jn', 'kn'], ['word', 'chi', 't', 'freq'], [10, 50, 100], [20]\n",
    "\n",
    "with open(Path('_/w2v.json')) as f:\n",
    "    w2v = json.load(f)\n",
    "with open(Path('_/merged.json')) as f:\n",
    "    merged = json.load(f)\n",
    "with open('_/results_old.json') as f:\n",
    "    results_old = json.load(f)\n",
    "with open('_/results.json') as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "for corpus in corpora:\n",
    "    try:\n",
    "        results[corpus]\n",
    "    except:\n",
    "        results[corpus] = {}\n",
    "    \n",
    "    for type_ in types:\n",
    "        try:\n",
    "            results[corpus][type_]\n",
    "        except:\n",
    "            results[corpus][type_] = {}\n",
    "        results[corpus][type_]['merged'] = merged[f'{corpus}-{type_}']\n",
    "        \n",
    "        for n_topic in n_topics:\n",
    "            try:\n",
    "                results[corpus][type_][str(n_topic)]\n",
    "            except:\n",
    "                results[corpus][type_][str(n_topic)] = {}\n",
    "            results[corpus][type_][str(n_topic)]['ll_per_token_norm'] = float(results_old[f'{corpus}-{type_}-{n_topic}-20']['ll'])\n",
    "            \n",
    "            results[corpus][type_][str(n_topic)]['20'] = {}\n",
    "            results[corpus][type_][str(n_topic)]['20']['silhouette'] = f\"{results_old[f'{corpus}-{type_}-{n_topic}-20']['silhouette']}\"\n",
    "\n",
    "with open('_/results.json', 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# migrate old data 'word', 'chi', 't'\n",
    "corpora, types, n_topics, n_keys = ['pt', 'tnc', 'wn', 'be', 'ny', 'sotu', 'ye', 'cn', 'dp', 'db'], ['word', 'chi', 't'], [10, 50, 100], [20]\n",
    "\n",
    "with open('/home/jin/lda/_/w2v.json') as f:\n",
    "    w2v = json.load(f)\n",
    "with open('/home/jin/lda/_/merged.json') as f:\n",
    "    merged = json.load(f)\n",
    "with open('/home/jin/lda/_/w2v.json') as f:\n",
    "    w2v = json.load(f)\n",
    "with open('_/results.json') as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "for corpus in corpora:\n",
    "    try:\n",
    "        results[corpus]\n",
    "    except:\n",
    "        results[corpus] = {}\n",
    "    \n",
    "    for type_ in types:\n",
    "        try:\n",
    "            results[corpus][type_]\n",
    "        except:\n",
    "            results[corpus][type_] = {}\n",
    "        results[corpus][type_]['merged'] = merged[f'{corpus}-{type_}']\n",
    "        \n",
    "        for n_topic in n_topics:\n",
    "            try:\n",
    "                results[corpus][type_][str(n_topic)]\n",
    "            except:\n",
    "                results[corpus][type_][str(n_topic)] = {}\n",
    "            results[corpus][type_][str(n_topic)]['ll_per_token_norm'] = float(w2v[f'{corpus}-{type_}-{n_topic}-20']['ll'])\n",
    "            \n",
    "            results[corpus][type_][str(n_topic)]['20'] = {}\n",
    "            results[corpus][type_][str(n_topic)]['20']['silhouette'] = f\"{w2v[f'{corpus}-{type_}-{n_topic}-20']['silhouette']}\"\n",
    "\n",
    "with open('_/results.json', 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# migrate old data wpe\n",
    "corpora, types, n_topics, n_keys = ['pt', 'tnc', 'wn', 'be', 'ny', 'sotu', 'ye', 'cn', 'dp', 'db'], ['wpe'], [10, 50, 100], [20]\n",
    "\n",
    "with open('/home/jin/lda/_/w2v.json') as f:\n",
    "    w2v = json.load(f)\n",
    "with open('/home/jin/lda/_/merged.json') as f:\n",
    "    merged = json.load(f)\n",
    "with open('/home/jin/lda/_/w2v.json') as f:\n",
    "    w2v = json.load(f)\n",
    "with open('_/results.json') as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "for corpus in corpora:\n",
    "    try:\n",
    "        results[corpus]\n",
    "    except:\n",
    "        results[corpus] = {}\n",
    "    \n",
    "    for type_ in types:\n",
    "        try:\n",
    "            results[corpus]['freq']\n",
    "        except:\n",
    "            results[corpus]['freq'] = {}\n",
    "        results[corpus]['freq']['merged'] = merged[f'{corpus}-{type_}']\n",
    "        \n",
    "        for n_topic in n_topics:\n",
    "            try:\n",
    "                results[corpus]['freq'][str(n_topic)]\n",
    "            except:\n",
    "                results[corpus]['freq'][str(n_topic)] = {}\n",
    "            results[corpus]['freq'][str(n_topic)]['ll_per_token_norm'] = float(w2v[f'{corpus}-{type_}-{n_topic}-20']['ll'])\n",
    "            \n",
    "            results[corpus]['freq'][str(n_topic)]['20'] = {}\n",
    "            results[corpus]['freq'][str(n_topic)]['20']['silhouette'] = f\"{w2v[f'{corpus}-{type_}-{n_topic}-20']['silhouette']}\"\n",
    "\n",
    "with open('_/results.json', 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:korean-env]",
   "language": "python",
   "name": "conda-env-korean-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
